# ğŸ“Š PX í”„ë¡œì íŠ¸ ë¡œê¹… ì‹œìŠ¤í…œ ê°€ì´ë“œ

## ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì•„í‚¤í…ì²˜](#ì•„í‚¤í…ì²˜)
3. [íŒŒë¼ë¯¸í„° ìƒì„¸](#íŒŒë¼ë¯¸í„°-ìƒì„¸)
4. [ì‚¬ìš© íŒ¨í„´](#ì‚¬ìš©-íŒ¨í„´)
5. [ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ](#ë§ˆì´ê·¸ë ˆì´ì…˜-ê°€ì´ë“œ)
6. [ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#ë² ìŠ¤íŠ¸-í”„ë™í‹°ìŠ¤)

## ê°œìš”

PX í”„ë¡œì íŠ¸ëŠ” RFS Framework 4.5.1 ê¸°ë°˜ì˜ í†µí•© ë¡œê¹… ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë™ê¸°/ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì§€ì›í•˜ë©°, êµ¬ì¡°í™”ëœ JSON ë¡œê¹…ì„ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- âœ… ë™ê¸°/ë¹„ë™ê¸° í†µí•© ì§€ì›
- âœ… êµ¬ì¡°í™”ëœ JSON ì¶œë ¥
- âœ… ì»¨í…ìŠ¤íŠ¸ ìë™ í¬í•¨
- âœ… ResultAsync íŒ¨í„´ í†µí•©
- âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘

## ì•„í‚¤í…ì²˜

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
src/shared/px_logging/
â”œâ”€â”€ __init__.py         # ë©”ì¸ export ëª¨ë“ˆ
â”œâ”€â”€ logger.py           # ResultAsync ê¸°ë°˜ ë¡œê±° (ë ˆê±°ì‹œ)
â”œâ”€â”€ unified_logger.py   # í†µí•© ë¡œê±° (í˜„ì¬ ì‚¬ìš©)
â””â”€â”€ error_tracker.py    # ì—ëŸ¬ ì¶”ì  ì‹œìŠ¤í…œ
```

### ë¡œê±° ìƒì„± ì²´ì¸
```python
get_logger(name, context) 
  â†’ get_async_result_logger(name, context)
    â†’ get_unified_logger(name, context)
      â†’ UnifiedLogger(name, context)
```

## íŒŒë¼ë¯¸í„° ìƒì„¸

### 1. ë¡œê±° ìƒì„±

#### get_logger(name, context)
| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|---------|------|------|------|------|
| `name` | `str` | âœ… | ë¡œê±° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ | `__name__`, `"app.service"` |
| `context` | `Dict[str, Any]` | âŒ | ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ | `{"service": "api", "version": "1.0"}` |

```python
from src.shared.px_logging import get_logger

# ê¸°ë³¸ ì‚¬ìš©
logger = get_logger(__name__)

# ì»¨í…ìŠ¤íŠ¸ í¬í•¨
logger = get_logger(__name__, {
    "service": "term_extraction",
    "environment": "production"
})
```

### 2. ë¡œê·¸ ë ˆë²¨ ë©”ì„œë“œ

#### ë™ê¸° ë©”ì„œë“œ
```python
logger.debug(message: str, **kwargs: Any) -> None
logger.info(message: str, **kwargs: Any) -> None
logger.warning(message: str, **kwargs: Any) -> None
logger.error(message: str, **kwargs: Any) -> None
logger.critical(message: str, **kwargs: Any) -> None
```

#### ë¹„ë™ê¸° ë©”ì„œë“œ
```python
await logger.debug_async(message: str, **kwargs: Any) -> ResultAsync[None, str]
await logger.info_async(message: str, **kwargs: Any) -> ResultAsync[None, str]
await logger.warning_async(message: str, **kwargs: Any) -> ResultAsync[None, str]
await logger.error_async(message: str, **kwargs: Any) -> ResultAsync[None, str]
await logger.critical_async(message: str, **kwargs: Any) -> ResultAsync[None, str]
```

### 3. íŠ¹ìˆ˜ ë©”ì„œë“œ

#### log_operation
ì‘ì—…ì˜ ì‹œì‘/ì™„ë£Œ/ì‹¤íŒ¨ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤.

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|------|--------|------|
| `operation` | `str` | - | ì‘ì—… ì´ë¦„ |
| `status` | `str` | `"started"` | ì‘ì—… ìƒíƒœ |
| `**metadata` | `Any` | - | ì¶”ê°€ ë©”íƒ€ë°ì´í„° |

```python
# ì‘ì—… ì‹œì‘
logger.log_operation("file_upload", "started", 
                    file_name="test.pdf", 
                    size_mb=2.5)

# ì‘ì—… ì™„ë£Œ
logger.log_operation("file_upload", "completed", 
                    file_name="test.pdf",
                    duration_ms=1250)

# ì‘ì—… ì‹¤íŒ¨
logger.log_operation("file_upload", "failed",
                    file_name="test.pdf",
                    error="Size limit exceeded")
```

#### log_performance
ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ë¡œê¹…í•©ë‹ˆë‹¤.

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ë‹¨ìœ„ | ì„¤ëª… |
|---------|------|------|------|
| `operation` | `str` | - | ì¸¡ì • ëŒ€ìƒ ì‘ì—… |
| `duration_ms` | `float` | ë°€ë¦¬ì´ˆ | ì‹¤í–‰ ì‹œê°„ |
| `**metadata` | `Any` | - | ì¶”ê°€ ì„±ëŠ¥ ì§€í‘œ |

```python
logger.log_performance(
    "database_query",
    duration_ms=45.2,
    query_type="SELECT",
    rows_returned=100,
    cache_hit=True
)
```

#### log_error_with_context
ì—ëŸ¬ì™€ ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¡œê¹…í•©ë‹ˆë‹¤.

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ì„¤ëª… |
|---------|------|------|
| `error` | `Exception` | ë°œìƒí•œ ì˜ˆì™¸ |
| `operation` | `str` | ì—ëŸ¬ ë°œìƒ ì‘ì—… |
| `**context` | `Any` | ë””ë²„ê¹… ì»¨í…ìŠ¤íŠ¸ |

```python
try:
    result = process_file(file_path)
except Exception as e:
    logger.log_error_with_context(
        e, 
        "file_processing",
        file_path=file_path,
        user_id=user_id,
        request_id=request_id
    )
```

### 4. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

#### with_context
ìƒˆë¡œìš´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•œ ë¡œê±°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
# ê¸°ë³¸ ë¡œê±°
logger = get_logger(__name__)

# ìš”ì²­ë³„ ë¡œê±°
request_logger = logger.with_context(
    request_id="abc-123",
    user_id=456,
    ip_address="192.168.1.1"
)

# ëª¨ë“  ë¡œê·¸ì— ì»¨í…ìŠ¤íŠ¸ í¬í•¨ë¨
request_logger.info("Processing request")
```

## ì‚¬ìš© íŒ¨í„´

### 1. ê¸°ë³¸ íŒ¨í„´

```python
from src.shared.px_logging import get_logger

class DocumentProcessor:
    def __init__(self):
        self.logger = get_logger(__name__)
    
    def process(self, document):
        self.logger.info("ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘", 
                        document_id=document.id,
                        document_type=document.type)
        
        try:
            # ì²˜ë¦¬ ë¡œì§
            result = self._do_process(document)
            
            self.logger.info("ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ",
                           document_id=document.id,
                           result_count=len(result))
            return result
            
        except Exception as e:
            self.logger.log_error_with_context(
                e, 
                "document_processing",
                document_id=document.id
            )
            raise
```

### 2. ë¹„ë™ê¸° íŒ¨í„´

```python
class AsyncDocumentProcessor:
    def __init__(self):
        self.logger = get_logger(__name__)
    
    async def process(self, document):
        # ë¹„ë™ê¸° ë¡œê¹… (ResultAsync ë°˜í™˜)
        await self.logger.info_async(
            "ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘",
            document_id=document.id
        )
        
        try:
            result = await self._async_process(document)
            
            await self.logger.info_async(
                "ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ",
                document_id=document.id,
                result_count=len(result)
            )
            return result
            
        except Exception as e:
            await self.logger.log_error_with_context_async(
                e,
                "async_processing",
                document_id=document.id
            )
            raise
```

### 3. ì„±ëŠ¥ ì¸¡ì • íŒ¨í„´

```python
import time

class PerformanceAwareProcessor:
    def __init__(self):
        self.logger = get_logger(__name__)
    
    def process_with_metrics(self, data):
        start_time = time.time()
        
        self.logger.log_operation("data_processing", "started",
                                 data_size=len(data))
        
        try:
            result = self._process(data)
            duration_ms = (time.time() - start_time) * 1000
            
            self.logger.log_performance(
                "data_processing",
                duration_ms=duration_ms,
                input_size=len(data),
                output_size=len(result),
                success=True
            )
            
            self.logger.log_operation("data_processing", "completed")
            return result
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            
            self.logger.log_performance(
                "data_processing",
                duration_ms=duration_ms,
                input_size=len(data),
                success=False,
                error_type=type(e).__name__
            )
            
            self.logger.log_operation("data_processing", "failed",
                                     error=str(e))
            raise
```

### 4. ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ íŒ¨í„´

```python
class RequestHandler:
    def __init__(self):
        self.base_logger = get_logger(__name__)
    
    async def handle_request(self, request):
        # ìš”ì²­ë³„ ë¡œê±° ìƒì„±
        logger = self.base_logger.with_context(
            request_id=request.id,
            user_id=request.user_id,
            endpoint=request.endpoint
        )
        
        logger.info("ìš”ì²­ ì²˜ë¦¬ ì‹œì‘")
        
        # ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì— ë¡œê±° ì „ë‹¬
        processor = DocumentProcessor(logger)
        result = await processor.process(request.document)
        
        logger.info("ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ", 
                   result_count=len(result))
        return result

class DocumentProcessor:
    def __init__(self, logger):
        # ì „ë‹¬ë°›ì€ ë¡œê±° ì‚¬ìš© (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
        self.logger = logger
    
    async def process(self, document):
        self.logger.debug("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘",
                         document_type=document.type)
        # ì²˜ë¦¬ ë¡œì§...
```

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### print â†’ logger ë³€í™˜

#### âŒ ì´ì „ (print ì‚¬ìš©)
```python
print(f"[DEBUG] Processing file: {file_name}")
print(f"[ERROR] Failed to process: {error}")
print(f"[INFO] Completed in {duration}ms")
```

#### âœ… í˜„ì¬ (logger ì‚¬ìš©)
```python
logger.debug("Processing file", file_name=file_name)
logger.error("Failed to process", error=error)
logger.info("Completed", duration_ms=duration)
```

### êµ¬ì¡°í™”ëœ ë¡œê¹…

#### âŒ ì´ì „ (ë¬¸ìì—´ í¬ë§·íŒ…)
```python
logger.info(f"User {user_id} uploaded {file_name} ({file_size} bytes)")
```

#### âœ… í˜„ì¬ (êµ¬ì¡°í™”ëœ íŒŒë¼ë¯¸í„°)
```python
logger.info("File uploaded",
           user_id=user_id,
           file_name=file_name,
           file_size=file_size)
```

### ì—ëŸ¬ ì²˜ë¦¬

#### âŒ ì´ì „
```python
try:
    result = process()
except Exception as e:
    print(f"Error: {e}")
    raise
```

#### âœ… í˜„ì¬
```python
try:
    result = process()
except Exception as e:
    logger.log_error_with_context(
        e,
        "process_operation",
        input_data=data,
        config=config
    )
    raise
```

## ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ë¡œê±° ì´ˆê¸°í™”
- ëª¨ë“ˆ ë ˆë²¨ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±
- `__name__`ì„ ì‚¬ìš©í•˜ì—¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìë™ ì„¤ì •

```python
# âœ… ì¢‹ì€ ì˜ˆ
logger = get_logger(__name__)

class MyService:
    def __init__(self):
        # ëª¨ë“ˆ ë¡œê±° ì¬ì‚¬ìš©
        pass

# âŒ ë‚˜ìœ ì˜ˆ
class MyService:
    def __init__(self):
        # ë§¤ë²ˆ ìƒˆ ë¡œê±° ìƒì„± (ë¹„íš¨ìœ¨ì )
        self.logger = get_logger(__name__)
```

### 2. êµ¬ì¡°í™”ëœ ë°ì´í„°
- ë¬¸ìì—´ í¬ë§·íŒ… ëŒ€ì‹  í‚¤ì›Œë“œ ì¸ì ì‚¬ìš©
- ê²€ìƒ‰ê³¼ í•„í„°ë§ì´ ì‰¬ìš´ êµ¬ì¡°í™”ëœ ë°ì´í„°

```python
# âœ… ì¢‹ì€ ì˜ˆ
logger.info("API í˜¸ì¶œ",
           method="POST",
           endpoint="/api/users",
           status_code=200,
           duration_ms=125.5)

# âŒ ë‚˜ìœ ì˜ˆ
logger.info(f"POST /api/users returned 200 in 125.5ms")
```

### 3. ì ì ˆí•œ ë¡œê·¸ ë ˆë²¨
- **DEBUG**: ê°œë°œ/ë””ë²„ê¹… ì •ë³´
- **INFO**: ì •ìƒ ì‘ë™ ì •ë³´
- **WARNING**: ì£¼ì˜ê°€ í•„ìš”í•œ ìƒí™©
- **ERROR**: ì—ëŸ¬ ë°œìƒ (ë³µêµ¬ ê°€ëŠ¥)
- **CRITICAL**: ì¹˜ëª…ì  ì—ëŸ¬ (ì‹œìŠ¤í…œ ì¤‘ë‹¨)

```python
logger.debug("ìºì‹œ ì¡°íšŒ", key=cache_key)
logger.info("ì‚¬ìš©ì ë¡œê·¸ì¸", user_id=user_id)
logger.warning("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ", usage_percent=85)
logger.error("API í˜¸ì¶œ ì‹¤íŒ¨", status_code=500)
logger.critical("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
```

### 4. ë¯¼ê° ì •ë³´ ì œì™¸
- ë¹„ë°€ë²ˆí˜¸, í† í°, ê°œì¸ì •ë³´ ë¡œê¹… ê¸ˆì§€
- í•„ìš”ì‹œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬

```python
# âœ… ì¢‹ì€ ì˜ˆ
logger.info("ì‚¬ìš©ì ì¸ì¦",
           user_id=user.id,
           email=mask_email(user.email))

# âŒ ë‚˜ìœ ì˜ˆ
logger.info("ì‚¬ìš©ì ì¸ì¦",
           password=user.password,  # ì ˆëŒ€ ê¸ˆì§€!
           credit_card=user.cc_number)  # ì ˆëŒ€ ê¸ˆì§€!
```

### 5. ì»¨í…ìŠ¤íŠ¸ í™œìš©
- ìš”ì²­ë³„, ì„¸ì…˜ë³„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
- ë””ë²„ê¹…ê³¼ ì¶”ì ì— ìœ ìš©í•œ ì •ë³´ í¬í•¨

```python
# ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ ì‹œ
request_logger = logger.with_context(
    request_id=generate_request_id(),
    session_id=session.id,
    user_id=user.id
)

# ì´í›„ ëª¨ë“  ë¡œê·¸ì— ì»¨í…ìŠ¤íŠ¸ ìë™ í¬í•¨
request_logger.info("ì²˜ë¦¬ ì‹œì‘")
request_logger.debug("ê²€ì¦ í†µê³¼")
request_logger.info("ì²˜ë¦¬ ì™„ë£Œ")
```

## ë¡œê·¸ ì¶œë ¥ í˜•ì‹

### JSON í˜•ì‹ (Production)
```json
{
  "timestamp": "2025-01-08T14:51:29.090602Z",
  "level": "INFO",
  "logger": "term_extraction.controller",
  "message": "File uploaded successfully",
  "module": "term_extraction_controller",
  "function": "process_documents",
  "line": 195,
  "extra_data": {
    "logger_type": "unified",
    "framework_version": "rfs-4.5.1",
    "file_name": "test.pdf",
    "file_size": 1024,
    "user_id": 123,
    "request_id": "abc-123"
  }
}
```

### í…ìŠ¤íŠ¸ í˜•ì‹ (Development)
```
2025-01-08 14:51:29 - term_extraction.controller - INFO - File uploaded successfully
```

## í™˜ê²½ë³„ ì„¤ì •

### Development
```python
setup_logging(
    level=LogLevel.DEBUG,
    enable_json=False  # ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í˜•ì‹
)
```

### Production
```python
setup_logging(
    level=LogLevel.INFO,
    enable_json=True  # êµ¬ì¡°í™”ëœ JSON í˜•ì‹
)
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ë¡œê·¸ê°€ ì¶œë ¥ë˜ì§€ ì•ŠìŒ
- ë¡œê·¸ ë ˆë²¨ í™•ì¸ (DEBUG ë¡œê·¸ëŠ” INFO ë ˆë²¨ì—ì„œ ì¶œë ¥ ì•ˆë¨)
- ë¡œê±° ì´ˆê¸°í™” í™•ì¸

### 2. JSON íŒŒì‹± ì—ëŸ¬
- íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ í™•ì¸
- ensure_ascii=False ì„¤ì • í™•ì¸

### 3. ì„±ëŠ¥ ì´ìŠˆ
- ê³¼ë„í•œ DEBUG ë¡œê¹… ì œê±°
- í° ê°ì²´ ë¡œê¹… ìì œ
- ë¹„ë™ê¸° ë¡œê¹… ê³ ë ¤

## ì°¸ê³  ìë£Œ

- [Python Logging Documentation](https://docs.python.org/3/library/logging.html)
- [RFS Framework Documentation](https://rfs-framework.readthedocs.io/)
- [Structured Logging Best Practices](https://www.structlog.org/)